{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e285eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pro 14\\.pyenv\\pyenv-win\\versions\\3.11.8\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Pro 14\\.pyenv\\pyenv-win\\versions\\3.11.8\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading data for cyber threat classification...\n",
      "Processing train split...\n",
      "Text directory: anno-ctr-lrec-coling-2024/AnnoCTR\\text\\train\n",
      "Found 70 text files in train split\n",
      "Processed 70 texts for threat classification\n",
      "Processing dev split...\n",
      "Text directory: anno-ctr-lrec-coling-2024/AnnoCTR\\text\\dev\n",
      "Found 16 text files in dev split\n",
      "Processed 16 texts for threat classification\n",
      "Processing test split...\n",
      "Text directory: anno-ctr-lrec-coling-2024/AnnoCTR\\text\\test\n",
      "Found 34 text files in test split\n",
      "Processed 34 texts for threat classification\n",
      "Data loaded successfully!\n",
      "Training threat classifier...\n",
      "\n",
      "train threat class distribution:\n",
      "label\n",
      "phishing      23\n",
      "other         19\n",
      "APT           16\n",
      "ransomware    12\n",
      "Name: count, dtype: int64\n",
      "Processed 70 examples for train\n",
      "\n",
      "dev threat class distribution:\n",
      "label\n",
      "other         4\n",
      "ransomware    4\n",
      "APT           4\n",
      "phishing      4\n",
      "Name: count, dtype: int64\n",
      "Processed 16 examples for dev\n",
      "\n",
      "test threat class distribution:\n",
      "label\n",
      "phishing      13\n",
      "ransomware    11\n",
      "APT            6\n",
      "other          4\n",
      "Name: count, dtype: int64\n",
      "Processed 34 examples for test\n",
      "Class weights to balance the dataset:\n",
      "  phishing: 0.7609\n",
      "  APT: 1.0938\n",
      "  other: 0.9211\n",
      "  ransomware: 1.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting threat classifier training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 05:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 1.323173999786377, 'eval_accuracy': 0.3235294117647059, 'eval_macro_f1': 0.20730994152046783, 'eval_phishing_precision': 0, 'eval_phishing_recall': 0.0, 'eval_phishing_f1': 0, 'eval_APT_precision': 0.2, 'eval_APT_recall': 0.25, 'eval_APT_f1': 0.22222222222222224, 'eval_other_precision': 0.5, 'eval_other_recall': 0.07692307692307693, 'eval_other_f1': 0.13333333333333336, 'eval_ransomware_precision': 0.3333333333333333, 'eval_ransomware_recall': 0.8181818181818182, 'eval_ransomware_f1': 0.4736842105263157, 'eval_runtime': 13.0445, 'eval_samples_per_second': 2.606, 'eval_steps_per_second': 0.383, 'epoch': 3.0}\n",
      "Threat classifier training complete!\n",
      "\n",
      "Example Prediction Results:\n",
      "Text: \n",
      "        A new ransomware campaign has been detected targeting healthcare organizations.\n",
      "        The...\n",
      "Predicted Threat Class: ransomware\n",
      "Confidence: 0.3823\n",
      "\n",
      "Top 3 Classes:\n",
      "  ransomware: 0.3823\n",
      "  APT: 0.2196\n",
      "  other: 0.2124\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import logging\n",
    "import joblib\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set paths to your AnnoCTR folders\n",
    "BASE_PATH = \"anno-ctr-lrec-coling-2024/AnnoCTR\"\n",
    "TEXT_PATH = os.path.join(BASE_PATH, \"text\")\n",
    "NER_PATH = os.path.join(BASE_PATH, \"ner_json\")\n",
    "LINKING_PATH = os.path.join(BASE_PATH, \"linking\")\n",
    "\n",
    "# Define the splits\n",
    "SPLITS = [\"train\", \"dev\", \"test\"]\n",
    "\n",
    "# Define threat classes (only keep phishing, APT, other, ransomware)\n",
    "THREAT_CLASSES = ['phishing', 'APT', 'other', 'ransomware']\n",
    "\n",
    "# Load and process data for threat classification\n",
    "def load_data_for_threat_classification():\n",
    "    datasets = {}\n",
    "    \n",
    "    for split in SPLITS:\n",
    "        text_path = os.path.join(TEXT_PATH, split)\n",
    "        ner_path = os.path.join(NER_PATH, split)\n",
    "        \n",
    "        # Check if directories exist\n",
    "        if not os.path.exists(text_path):\n",
    "            print(f\"Warning: Text path {text_path} does not exist\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing {split} split...\")\n",
    "        print(f\"Text directory: {text_path}\")\n",
    "        \n",
    "        texts = []\n",
    "        threat_labels = []\n",
    "        \n",
    "        # Count files for progress reporting\n",
    "        txt_files = [f for f in os.listdir(text_path) if f.endswith('.txt')]\n",
    "        print(f\"Found {len(txt_files)} text files in {split} split\")\n",
    "        \n",
    "        for filename in txt_files:\n",
    "            # Load text\n",
    "            txt_file = os.path.join(text_path, filename)\n",
    "            try:\n",
    "                with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "                    raw_text = f.read()\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {txt_file}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Load NER entities to help determine threat type\n",
    "            ner_file = os.path.join(ner_path, filename.replace('.txt', '.json'))\n",
    "            entity_types = set()\n",
    "            \n",
    "            if os.path.exists(ner_file):\n",
    "                try:\n",
    "                    with open(ner_file, 'r', encoding='utf-8') as f:\n",
    "                        ner_data_file = json.load(f)\n",
    "                        \n",
    "                        for entity in ner_data_file.get('entities', []):\n",
    "                            entity_type = entity.get('label', '').lower()\n",
    "                            entity_types.add(entity_type)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing NER file {ner_file}: {e}\")\n",
    "            \n",
    "            # Determine threat type based on entity types and text content\n",
    "            threat_type = 'other'  # Default\n",
    "            \n",
    "            # Simple heuristic: check for keywords in text and entity types\n",
    "            text_lower = raw_text.lower()\n",
    "            # Updated to only check for the classes we want\n",
    "            if 'phishing' in text_lower:\n",
    "                threat_type = 'phishing'\n",
    "            elif 'apt' in entity_types or 'APT' in raw_text:\n",
    "                threat_type = 'APT'\n",
    "            elif 'ransomware' in text_lower:\n",
    "                threat_type = 'ransomware'\n",
    "            # Remove checks for spyware, botnet, and exploit classes\n",
    "            \n",
    "            texts.append(raw_text)\n",
    "            threat_labels.append(threat_type)\n",
    "        \n",
    "        # Print stats\n",
    "        print(f\"Processed {len(texts)} texts for threat classification\")\n",
    "        \n",
    "        # Verify we have data\n",
    "        if not texts:\n",
    "            print(f\"Warning: No text data found for {split} split\")\n",
    "            continue\n",
    "        \n",
    "        # Create threat classification dataframe\n",
    "        threat_df = pd.DataFrame({\n",
    "            'text': texts,\n",
    "            'label': threat_labels\n",
    "        })\n",
    "        \n",
    "        datasets[split] = threat_df\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Fixed: Updated WeightedLossTrainer class to handle both cases with and without num_items_in_batch\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            # Explicitly convert to float32 to match the expected datatype\n",
    "            weight = torch.tensor(self.class_weights, device=logits.device, dtype=torch.float32)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def train_threat_classifier(datasets, model_name='bert-base-uncased'):\n",
    "    \"\"\"\n",
    "    Train a threat classification model using the provided datasets\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Initialize label encoder\n",
    "    threat_encoder = LabelEncoder()\n",
    "    threat_encoder.fit(THREAT_CLASSES)\n",
    "    \n",
    "    # Save encoder\n",
    "    os.makedirs(\"./threat_model_v2\", exist_ok=True)\n",
    "    joblib.dump(threat_encoder, \"./threat_model_v2/threat_encoder.joblib\")\n",
    "    \n",
    "    # Process datasets for threat classification\n",
    "    processed_datasets = {}\n",
    "    \n",
    "    # Set the device to CPU explicitly if needed due to dtype issues\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    for split, threat_df in datasets.items():\n",
    "        threat_labels = threat_encoder.transform(threat_df['label'])\n",
    "        \n",
    "        # Print distribution\n",
    "        print(f\"\\n{split} threat class distribution:\")\n",
    "        print(pd.Series(threat_df['label']).value_counts())\n",
    "        \n",
    "        # Create dataset\n",
    "        examples = []\n",
    "        \n",
    "        for i in range(len(threat_df)):\n",
    "            text = threat_df['text'].iloc[i]\n",
    "            label = int(threat_labels[i])\n",
    "            \n",
    "            # Tokenize\n",
    "            # Tokenize with explicit float32 conversion\n",
    "            tokenized = tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Ensure attention mask is properly formatted\n",
    "            attention_mask = tokenized[\"attention_mask\"][0].tolist()\n",
    "            \n",
    "            examples.append({\n",
    "                \"input_ids\": tokenized[\"input_ids\"][0].tolist(),\n",
    "                \"attention_mask\": tokenized[\"attention_mask\"][0].tolist(),\n",
    "                \"labels\": label\n",
    "            })\n",
    "        \n",
    "        processed_datasets[split] = Dataset.from_list(examples)\n",
    "        print(f\"Processed {len(examples)} examples for {split}\")\n",
    "    \n",
    "    # Calculate class weights for balancing\n",
    "    train_labels = datasets['train']['label'].values\n",
    "    # Make sure all classes are represented in the weight calculation\n",
    "    unique_classes = np.array(THREAT_CLASSES)\n",
    "    train_label_counts = pd.Series(train_labels).value_counts().reindex(unique_classes, fill_value=0)\n",
    "    \n",
    "    # Manually calculate weights - inverse of frequency\n",
    "    total_samples = len(train_labels)\n",
    "    class_weights = {}\n",
    "    for i, cls in enumerate(THREAT_CLASSES):\n",
    "        count = train_label_counts[cls]\n",
    "        if count > 0:\n",
    "            weight = total_samples / (len(THREAT_CLASSES) * count)\n",
    "        else:\n",
    "            weight = 1.0  # Default weight for classes not in training set\n",
    "        class_weights[i] = weight\n",
    "    \n",
    "    # Convert to list in the order of class indices\n",
    "    weight_list = [class_weights[i] for i in range(len(THREAT_CLASSES))]\n",
    "    \n",
    "    print(\"Class weights to balance the dataset:\")\n",
    "    for i, weight in enumerate(weight_list):\n",
    "        print(f\"  {THREAT_CLASSES[i]}: {weight:.4f}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(THREAT_CLASSES)\n",
    "    )\n",
    "    \n",
    "    # Define training arguments with backward compatibility\n",
    "    try:\n",
    "        # Option 1: Try with simpler arguments first\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./threat_model_v2\",\n",
    "            num_train_epochs=3,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=\"./threat_model_v2/logs\",\n",
    "            logging_steps=100\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"First training args approach failed: {e}\")\n",
    "        # Option 2: Try with explicit evaluation but no best model loading\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./threat_model_v2\",\n",
    "            num_train_epochs=3,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=0.01,\n",
    "            eval_steps=100,\n",
    "            save_steps=100,\n",
    "            logging_steps=100\n",
    "        )\n",
    "    \n",
    "    # Define compute_metrics\n",
    "    def compute_threat_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        accuracy = (predictions == labels).mean()\n",
    "        \n",
    "        # Add class-wise metrics\n",
    "        class_metrics = {}\n",
    "        for i, class_name in enumerate(THREAT_CLASSES):\n",
    "            # Calculate precision and recall for each class\n",
    "            class_preds = (predictions == i)\n",
    "            class_labels = (labels == i)\n",
    "            \n",
    "            true_pos = (class_preds & class_labels).sum()\n",
    "            false_pos = (class_preds & ~class_labels).sum()\n",
    "            false_neg = (~class_preds & class_labels).sum()\n",
    "            \n",
    "            precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "            recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            class_metrics[f\"{class_name}_precision\"] = precision\n",
    "            class_metrics[f\"{class_name}_recall\"] = recall\n",
    "            class_metrics[f\"{class_name}_f1\"] = f1\n",
    "        \n",
    "        # Calculate macro F1 (average of F1 scores across all classes)\n",
    "        f1_scores = [class_metrics[f\"{class_name}_f1\"] for class_name in THREAT_CLASSES]\n",
    "        macro_f1 = sum(f1_scores) / len(f1_scores)\n",
    "        \n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            **class_metrics\n",
    "        }\n",
    "    \n",
    "    # Initialize Weighted Trainer\n",
    "    trainer = WeightedLossTrainer(\n",
    "        class_weights=weight_list,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=processed_datasets[\"train\"],\n",
    "        eval_dataset=processed_datasets[\"dev\"],\n",
    "        compute_metrics=compute_threat_metrics\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting threat classifier training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    if \"test\" in processed_datasets:\n",
    "        test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "        print(f\"Test Results: {test_results}\")\n",
    "    \n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(\"./threat_model_v2\")\n",
    "    tokenizer.save_pretrained(\"./threat_model_v2\")\n",
    "    \n",
    "    return model, tokenizer, threat_encoder\n",
    "\n",
    "def predict_threat(text, model=None, tokenizer=None, threat_encoder=None):\n",
    "    \"\"\"\n",
    "    Make a threat classification prediction for a single text\n",
    "    \n",
    "    Args:\n",
    "        text (str): The cyber threat report text to classify\n",
    "        model: The trained threat classification model (will load if None)\n",
    "        tokenizer: The tokenizer for the model (will load if None)\n",
    "        threat_encoder: The LabelEncoder for mapping class indices to names (will load if None)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results with class probabilities\n",
    "    \"\"\"\n",
    "    # Load model components if not provided\n",
    "    if model is None or tokenizer is None or threat_encoder is None:\n",
    "        model_path = \"./threat_model_v2\"\n",
    "        \n",
    "        if not os.path.exists(model_path):\n",
    "            raise ValueError(\"Model directory not found. Please train the model first.\")\n",
    "        \n",
    "        if model is None:\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        \n",
    "        if tokenizer is None:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "        if threat_encoder is None:\n",
    "            encoder_path = os.path.join(model_path, \"threat_encoder.joblib\")\n",
    "            if not os.path.exists(encoder_path):\n",
    "                raise ValueError(\"Threat encoder not found. Please train the model first.\")\n",
    "            threat_encoder = joblib.load(encoder_path)\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Process logits\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)[0]\n",
    "    \n",
    "    # Get prediction\n",
    "    predicted_class_idx = torch.argmax(logits, dim=1).item()\n",
    "    predicted_class = threat_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    confidence = probabilities[predicted_class_idx].item()\n",
    "    \n",
    "    # Prepare detailed results\n",
    "    class_probabilities = {\n",
    "        threat_encoder.inverse_transform([i])[0]: prob.item()\n",
    "        for i, prob in enumerate(probabilities)\n",
    "    }\n",
    "    \n",
    "    # Sort classes by probability (descending)\n",
    "    sorted_probs = sorted(\n",
    "        class_probabilities.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"confidence\": confidence,\n",
    "        \"class_probabilities\": class_probabilities,\n",
    "        \"top_classes\": sorted_probs[:3]  # Top 3 most likely classes\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the threat classification pipeline\n",
    "    \"\"\"\n",
    "    print(\"Loading data for cyber threat classification...\")\n",
    "    try:\n",
    "        datasets = load_data_for_threat_classification()\n",
    "        print(\"Data loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    print(\"Training threat classifier...\")\n",
    "    try:\n",
    "        model, tokenizer, threat_encoder = train_threat_classifier(datasets)\n",
    "        print(\"Threat classifier training complete!\")\n",
    "        \n",
    "        # Example prediction\n",
    "        example_text = \"\"\"\n",
    "        A new ransomware campaign has been detected targeting healthcare organizations.\n",
    "        The malware encrypts critical patient data and demands payment in cryptocurrency.\n",
    "        Initial infection vectors include phishing emails with malicious attachments and\n",
    "        exploitation of vulnerabilities in outdated VPN software.\n",
    "        \"\"\"\n",
    "        \n",
    "        result = predict_threat(example_text, model, tokenizer, threat_encoder)\n",
    "        \n",
    "        print(\"\\nExample Prediction Results:\")\n",
    "        print(f\"Text: {example_text[:100]}...\")\n",
    "        print(f\"Predicted Threat Class: {result['predicted_class']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "        \n",
    "        print(\"\\nTop 3 Classes:\")\n",
    "        for cls, prob in result['top_classes']:\n",
    "            print(f\"  {cls}: {prob:.4f}\")\n",
    "            \n",
    "        return model, tokenizer, threat_encoder\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training or prediction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
