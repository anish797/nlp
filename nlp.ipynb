{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2364ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2e5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "test_data = pd.read_csv('UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae81680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (175341, 45)\n",
      "Testing data shape: (82332, 45)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98db31aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7890345\n",
      "3704940\n"
     ]
    }
   ],
   "source": [
    "print(train_data.size)\n",
    "print(test_data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567ac00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in dataset:\n",
      "['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat', 'label']\n",
      "\n",
      "Data types:\n",
      "id                     int64\n",
      "dur                  float64\n",
      "proto                 object\n",
      "service               object\n",
      "state                 object\n",
      "spkts                  int64\n",
      "dpkts                  int64\n",
      "sbytes                 int64\n",
      "dbytes                 int64\n",
      "rate                 float64\n",
      "sttl                   int64\n",
      "dttl                   int64\n",
      "sload                float64\n",
      "dload                float64\n",
      "sloss                  int64\n",
      "dloss                  int64\n",
      "sinpkt               float64\n",
      "dinpkt               float64\n",
      "sjit                 float64\n",
      "djit                 float64\n",
      "swin                   int64\n",
      "stcpb                  int64\n",
      "dtcpb                  int64\n",
      "dwin                   int64\n",
      "tcprtt               float64\n",
      "synack               float64\n",
      "ackdat               float64\n",
      "smean                  int64\n",
      "dmean                  int64\n",
      "trans_depth            int64\n",
      "response_body_len      int64\n",
      "ct_srv_src             int64\n",
      "ct_state_ttl           int64\n",
      "ct_dst_ltm             int64\n",
      "ct_src_dport_ltm       int64\n",
      "ct_dst_sport_ltm       int64\n",
      "ct_dst_src_ltm         int64\n",
      "is_ftp_login           int64\n",
      "ct_ftp_cmd             int64\n",
      "ct_flw_http_mthd       int64\n",
      "ct_src_ltm             int64\n",
      "ct_srv_dst             int64\n",
      "is_sm_ips_ports        int64\n",
      "attack_cat            object\n",
      "label                  int64\n",
      "dtype: object\n",
      "\n",
      "Training label distribution:\n",
      "label\n",
      "1    119341\n",
      "0     56000\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    0.680622\n",
      "0    0.319378\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test label distribution:\n",
      "label\n",
      "1    45332\n",
      "0    37000\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    0.5506\n",
      "0    0.4494\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Attack categories in training data:\n",
      "attack_cat\n",
      "Normal            56000\n",
      "Generic           40000\n",
      "Exploits          33393\n",
      "Fuzzers           18184\n",
      "DoS               12264\n",
      "Reconnaissance    10491\n",
      "Analysis           2000\n",
      "Backdoor           1746\n",
      "Shellcode          1133\n",
      "Worms               130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attack categories in test data:\n",
      "attack_cat\n",
      "Normal            37000\n",
      "Generic           18871\n",
      "Exploits          11132\n",
      "Fuzzers            6062\n",
      "DoS                4089\n",
      "Reconnaissance     3496\n",
      "Analysis            677\n",
      "Backdoor            583\n",
      "Shellcode           378\n",
      "Worms                44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in training data:\n",
      "0\n",
      "\n",
      "Summary statistics for numerical features (sample):\n",
      "                  id            dur          spkts          dpkts  \\\n",
      "count  175341.000000  175341.000000  175341.000000  175341.000000   \n",
      "mean    87671.000000       1.359389      20.298664      18.969591   \n",
      "std     50616.731112       6.480249     136.887597     110.258271   \n",
      "min         1.000000       0.000000       1.000000       0.000000   \n",
      "25%     43836.000000       0.000008       2.000000       0.000000   \n",
      "50%     87671.000000       0.001582       2.000000       2.000000   \n",
      "75%    131506.000000       0.668069      12.000000      10.000000   \n",
      "max    175341.000000      59.999989    9616.000000   10974.000000   \n",
      "\n",
      "             sbytes  \n",
      "count  1.753410e+05  \n",
      "mean   8.844844e+03  \n",
      "std    1.747656e+05  \n",
      "min    2.800000e+01  \n",
      "25%    1.140000e+02  \n",
      "50%    4.300000e+02  \n",
      "75%    1.418000e+03  \n",
      "max    1.296523e+07  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumns in dataset:\")\n",
    "print(train_data.columns.tolist())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(train_data['label'].value_counts())\n",
    "print(train_data['label'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(test_data['label'].value_counts())\n",
    "print(test_data['label'].value_counts(normalize=True))\n",
    "\n",
    "# Check attack categories if available\n",
    "if 'attack_cat' in train_data.columns:\n",
    "    print(\"\\nAttack categories in training data:\")\n",
    "    print(train_data['attack_cat'].value_counts())\n",
    "    \n",
    "    print(\"\\nAttack categories in test data:\")\n",
    "    print(test_data['attack_cat'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_data.isnull().sum().sum())\n",
    "\n",
    "# Get basic statistics for numerical features\n",
    "print(\"\\nSummary statistics for numerical features (sample):\")\n",
    "print(train_data.describe().iloc[:, :5])  # First 5 columns only for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d658d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['id', 'attack_cat', 'label'], axis=1)\n",
    "y_train = train_data['label']  # For binary classification\n",
    "\n",
    "\n",
    "X_test = test_data.drop(['id', 'attack_cat', 'label'], axis=1)\n",
    "y_test = test_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8076f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['proto', 'service', 'state']\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=False)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "# Ensure train and test have the same columns\n",
    "train_cols = set(X_train_encoded.columns)\n",
    "test_cols = set(X_test_encoded.columns)\n",
    "\n",
    "# Add missing columns to test set\n",
    "for col in train_cols - test_cols:\n",
    "    X_test_encoded[col] = 0\n",
    "\n",
    "# Add missing columns to train set\n",
    "for col in test_cols - train_cols:\n",
    "    X_train_encoded[col] = 0\n",
    "\n",
    "X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4350b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SMOTE-balanced XGBoost model...\n",
      "Evaluating model on test set...\n",
      "Model Performance:\n",
      "Accuracy: 0.9119\n",
      "ROC AUC: 0.9846\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31501  5499]\n",
      " [ 1752 43580]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90     37000\n",
      "           1       0.89      0.96      0.92     45332\n",
      "\n",
      "    accuracy                           0.91     82332\n",
      "   macro avg       0.92      0.91      0.91     82332\n",
      "weighted avg       0.91      0.91      0.91     82332\n",
      "\n",
      "Saving model and preprocessing components...\n",
      "Scaler saved as 'network_intrusion_scaler.pkl'\n",
      "SMOTE model saved as 'network_intrusion_smote_model.pkl'\n",
      "Feature names saved as 'model_features.txt'\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define best parameters for XGBoost (based on your original hyperparameter tuning)\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'gamma': 0.2,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'scale_pos_weight': (y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train the SMOTE-balanced XGBoost model\n",
    "print(\"Training SMOTE-balanced XGBoost model...\")\n",
    "smote_model = xgb.XGBClassifier(**best_params)\n",
    "smote_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "print(\"Evaluating model on test set...\")\n",
    "y_pred = smote_model.predict(X_test_scaled)\n",
    "y_prob = smote_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC: {auc:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the entire pipeline for later use\n",
    "print(\"Saving model and preprocessing components...\")\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'network_intrusion_scaler.pkl')\n",
    "print(\"Scaler saved as 'network_intrusion_scaler.pkl'\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(smote_model, 'network_intrusion_smote_model.pkl')\n",
    "print(\"SMOTE model saved as 'network_intrusion_smote_model.pkl'\")\n",
    "\n",
    "# Optional: Save column names for future reference \n",
    "with open('model_features.txt', 'w') as f:\n",
    "    for feature in X_train_encoded.columns:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "print(\"Feature names saved as 'model_features.txt'\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
